# PR√ÅCTICA 4: Asistentes basados en lenguaje


Este proyecto implementa un asistente virtual acad√©mico que utiliza un modelo de lenguaje basado en **Ollama** para responder preguntas relacionadas con un conjunto de conocimientos previamente cargados. El sistema soporta dos modos de operaci√≥n principales: **RAG (Retrieve and Generate)** y **Chain of Thought (CoT)**, el cual simula un proceso de razonamiento paso a paso antes de responder.

## üóÇÔ∏è Estructura del Proyecto
La estructura del proyecto es la siguiente:

- knowledge_base/
   - professors: Parte de la base de conocimiento con la informaci√≥n de los docentes.
   - students: Parte de la base de conocimiento con la informaci√≥n de los alumnos.
   - subjects: Parte de la base de conocimiento con la informaci√≥n de las asignaturas.



- src/
   - inference_engine.py: Implementaci√≥n del modo CoT 
   - rag.py: Implementaci√≥n del m√≥dulo de RAG
   - utils.py: Utilidades para procesar la base de conocimiento.



- main.py: Punto de entrada principal del proyecto.

- requirements.txt: Lista de dependencias necesarias.

- pyproject.toml: Archivo de configuraci√≥n del proyecto.

- uv.lock: Archivo de bloqueo para la gesti√≥n de dependencias.

## üõ†Ô∏è Instalaci√≥n y Configuraci√≥n

Aseg√∫rate de tener instalado lo siguiente en tu sistema:
- Python 3.8 o superior
- Las dependencias del proyecto listadas en `requirements.txt`
    ```bash
    pip install -r requirements.txt
Las dependencias incluyen:

- `click`: Para la interfaz de l√≠nea de comandos.
- `ollama`: Cliente para interactuar con modelos de Ollama. Este proyecto utiliza el modelo `llama3.2:1b` de Ollama. Aseg√∫rate de que el modelo est√© instalado en tu entorno antes de continuar.
- `uv`: Para ejecutar scripts desde un entorno virtual.

### C√≥mo ejecutar el programa

1. Abre una terminal o consola de comandos.
2. Navega a la carpeta donde se encuentra el archivo `main.py` usando el comando `cd`.
     ```bash
     cd /ruta/a/tu/proyecto
     ```
3. Ejecuta el programa con el siguiente comando:  
   ```bash
   uv run python main.py knowledge_base

4. Opciones Adicionales:

El asistente acepta las siguientes opciones:

- `--model`: Especifica el modelo de lenguaje a utilizar (por defecto: llama3.2:1b).
- `--mode`: Define el modo de operaci√≥n. Los valores posibles son:
   - rag: Recupera contexto relevante antes de generar una respuesta.
   - cot: Simula razonamiento paso a paso antes de responder.
- `--verbose`: Muestra detalles adicionales del proceso de ejecuci√≥n.

Ejemplo:
```bash
uv run python main.py knowledge_base --mode=cot --verbose
```

## üß† Modos de Operaci√≥n

### RAG (Retrieve and Generate)
En este modo, el asistente busca fragmentos relevantes de la base de conocimiento y los utiliza para responder la consulta del usuario.

### Chain of Thought (CoT)
En este modo, el asistente simula un proceso de razonamiento antes de responder. Genera pasos intermedios para analizar la consulta y organizar su respuesta de manera estructurada.

## üìö Base de Conocimiento
Los archivos de la carpeta `knowledge_base` contienen informaci√≥n estructurada sobre profesores, estudiantes y asignaturas. Durante la ejecuci√≥n, esta informaci√≥n es procesada para extraer palabras clave y contextos relevantes.

## üß™ Ejemplos de Consultas
Al ejecutar el asistente, puedes realizar preguntas como:
- Which courses does Juan Perez take?
- Tell me about Modern Physics.
- Who teaches Data Structures and Algorithms?

## üë• Integrantes

- Mario L√≥pez D√≠az
- Ignacio Guti√©rrez S√°nchez